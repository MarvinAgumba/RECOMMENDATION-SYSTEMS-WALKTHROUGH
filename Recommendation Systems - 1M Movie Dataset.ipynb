{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Developing Recommendation Systems from Real-World Datasets\n",
    "\n",
    "## 1M Movie Dataset\n",
    "We shall get the chance to create a more complete recommender system pipeline to obtain the top recommendations for a specific user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100836 entries, 0 to 100835\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   userId     100836 non-null  int64  \n",
      " 1   movieId    100836 non-null  int64  \n",
      " 2   rating     100836 non-null  float64\n",
      " 3   timestamp  100836 non-null  int64  \n",
      "dtypes: float64(1), int64(3)\n",
      "memory usage: 3.1 MB\n"
     ]
    }
   ],
   "source": [
    "#Loading our dataset\n",
    "import pandas as pd\n",
    "df = pd.read_csv('ratings.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "new_df = df.drop(columns='timestamp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We transform the dataset into something compatible with `surprise`. In order to do this, we are going to need `Reader` and `Dataset` classes. There's a method in `Dataset` specifically for loading dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Reader, Dataset\n",
    "\n",
    "# read in values as Surprise dataset \n",
    "reader = Reader()\n",
    "data = Dataset.load_from_df(new_df,reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at how many users and items we have in our dataset. If using neighborhood-based methods, this will help us determine whether or not we should perform user-user or item-item similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users:  610 \n",
      "\n",
      "Number of items:  9724\n"
     ]
    }
   ],
   "source": [
    "dataset = data.build_full_trainset()\n",
    "print('Number of users: ', dataset.n_users, '\\n')\n",
    "print('Number of items: ', dataset.n_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Determine the best model**: Now, compare the different models and see which ones perform best. For consistency sake, use RMSE to evaluate models. Remember to cross-validate! Can you get a model with a higher average RMSE on test data than 0.869?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing relevant libraries\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.prediction_algorithms import SVD\n",
    "from surprise.prediction_algorithms import KNNWithMeans, KNNBasic, KNNBaseline\n",
    "from surprise.model_selection import GridSearchCV\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Perform a gridsearch with SVD\n",
    "# â° This cell may take several minutes to run\n",
    "params = {'n_factors': [20, 50, 100],\n",
    "         'reg_all': [0.02, 0.05, 0.1]}\n",
    "g_s_svd = GridSearchCV(SVD,param_grid=params,n_jobs=-1)\n",
    "g_s_svd.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.8694549447006225, 'mae': 0.6680067046870862}\n",
      "{'rmse': {'n_factors': 100, 'reg_all': 0.05}, 'mae': {'n_factors': 50, 'reg_all': 0.05}}\n"
     ]
    }
   ],
   "source": [
    "# print out optimal parameters for SVD after GridSearch\n",
    "print(g_s_svd.best_score)\n",
    "print(g_s_svd.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validating with KNNBasic\n",
    "knn_basic = KNNBasic(sim_options={'name':'pearson', 'user_based':True})\n",
    "cv_knn_basic = cross_validate(knn_basic, data, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('test_rmse', array([0.97399348, 0.97279161, 0.97047477, 0.97423627, 0.97250206]))\n",
      "('test_mae', array([0.75338593, 0.75097489, 0.74605343, 0.75295196, 0.75163522]))\n",
      "('fit_time', (1.0879662036895752, 1.1078801155090332, 1.1071605682373047, 1.0629935264587402, 1.031749963760376))\n",
      "('test_time', (1.6417181491851807, 1.6572823524475098, 1.6419687271118164, 1.6733195781707764, 1.642467737197876))\n",
      "-----------------------\n",
      "0.9727996365991605\n"
     ]
    }
   ],
   "source": [
    "# # print out the average RMSE score for the test set\n",
    "for i in cv_knn_basic.items():\n",
    "    print(i)\n",
    "print('-----------------------')\n",
    "print(np.mean(cv_knn_basic['test_rmse']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "# cross validating with KNNBaseline\n",
    "knn_baseline = KNNBaseline(sim_options={'name':'pearson', 'user_based':True})\n",
    "cv_knn_baseline = cross_validate(knn_baseline,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('test_rmse', array([0.88583506, 0.87480521, 0.87294868, 0.8774304 , 0.87314251]))\n",
      "('test_mae', array([0.67660928, 0.66894125, 0.66541226, 0.67036099, 0.66851752]))\n",
      "('fit_time', (1.1541850566864014, 1.2625689506530762, 1.3072295188903809, 1.278538465499878, 1.2829015254974365))\n",
      "('test_time', (2.310779571533203, 2.4475972652435303, 2.4624223709106445, 2.4573185443878174, 2.4610376358032227))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8768323703793162"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print out the average score for the test set\n",
    "for i in cv_knn_baseline.items():\n",
    "    print(i)\n",
    "\n",
    "np.mean(cv_knn_baseline['test_rmse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Based off these outputs, it seems like the best performing model is the SVD model with `n_factors = 50` and a regularization rate of 0.05. Use that model or if you found one that performs better, feel free to use that to make some predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Making Recommendations:** It's important that the output for the recommendation is interpretable to people. Rather than returning the `movie_id` values, it would be far more valuable to return the actual title of the movie. As a first step, let's read in the movies to a dataframe and take a peek at what information we have about them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                               title  \\\n",
       "0        1                    Toy Story (1995)   \n",
       "1        2                      Jumanji (1995)   \n",
       "2        3             Grumpier Old Men (1995)   \n",
       "3        4            Waiting to Exhale (1995)   \n",
       "4        5  Father of the Bride Part II (1995)   \n",
       "\n",
       "                                        genres  \n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                   Adventure|Children|Fantasy  \n",
       "2                               Comedy|Romance  \n",
       "3                         Comedy|Drama|Romance  \n",
       "4                                       Comedy  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_movies = pd.read_csv('movies.csv')\n",
    "df_movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x1a3962b9eb0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#making simple predictions\n",
    "svd = SVD(n_factors= 50, reg_all=0.05)\n",
    "svd.fit(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(uid=2, iid=4, r_ui=None, est=2.993807613080075, details={'was_impossible': False})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd.predict(2, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This prediction value is a tuple and each of the values within it can be accessed by way of indexing. Now let's put our knowledge of recommendation systems to do something interesting: making predictions for a new user!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obtaining User Ratings**: It's great that we have working models and everything, but wouldn't it be nice to get to recommendations specifically tailored to your preferences? That's what we'll be doing now. The first step is to create a function that allows us to pick randomly selected movies. The function should present users with a movie and ask them to rate it. If they have not seen the movie, they should be able to skip rating it. \n",
    "\n",
    "The function `movie_rater()` should take as parameters: \n",
    "\n",
    "* `movie_df`: DataFrame - a dataframe containing the movie ids, name of movie, and genres\n",
    "* `num`: int - number of ratings\n",
    "* `genre`: string - a specific genre from which to draw movies\n",
    "\n",
    "The function returns:\n",
    "* rating_list : list - a collection of dictionaries in the format of {'userId': int , 'movieId': int , 'rating': float}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def movie_rater(movie_df,num, genre=None):\n",
    "    userID = 1000\n",
    "    rating_list = []\n",
    "    while num > 0:\n",
    "        if genre:\n",
    "            movie = movie_df[movie_df['genres'].str.contains(genre)].sample(1)\n",
    "        else:\n",
    "            movie = movie_df.sample(1)\n",
    "        print(movie)\n",
    "        rating = input('How do you rate this movie on a scale of 1-5, press n if you have not seen :\\n')\n",
    "        if rating == 'n':\n",
    "            continue\n",
    "        else:\n",
    "            rating_one_movie = {'userId':userID,'movieId':movie['movieId'].values[0],'rating':rating}\n",
    "            rating_list.append(rating_one_movie) \n",
    "            num -= 1\n",
    "    return rating_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      movieId                        title                    genres\n",
      "5921    33830  Herbie: Fully Loaded (2005)  Adventure|Comedy|Romance\n",
      "How do you rate this movie on a scale of 1-5, press n if you have not seen :\n",
      "n\n",
      "      movieId                     title  \\\n",
      "7180    72226  Fantastic Mr. Fox (2009)   \n",
      "\n",
      "                                         genres  \n",
      "7180  Adventure|Animation|Children|Comedy|Crime  \n",
      "How do you rate this movie on a scale of 1-5, press n if you have not seen :\n",
      "n\n",
      "      movieId             title          genres\n",
      "3881     5454  Mo' Money (1992)  Comedy|Romance\n",
      "How do you rate this movie on a scale of 1-5, press n if you have not seen :\n",
      "n\n",
      "      movieId                                    title         genres\n",
      "8050    98633  My Lucky Stars (Fuk sing go jiu) (1985)  Action|Comedy\n",
      "How do you rate this movie on a scale of 1-5, press n if you have not seen :\n",
      "n\n",
      "      movieId                       title                    genres\n",
      "2150     2863  Hard Day's Night, A (1964)  Adventure|Comedy|Musical\n",
      "How do you rate this movie on a scale of 1-5, press n if you have not seen :\n",
      "n\n",
      "      movieId                       title  genres\n",
      "5075     7983  Broadway Danny Rose (1984)  Comedy\n",
      "How do you rate this movie on a scale of 1-5, press n if you have not seen :\n",
      "n\n",
      "      movieId           title        genres\n",
      "2619     3504  Network (1976)  Comedy|Drama\n",
      "How do you rate this movie on a scale of 1-5, press n if you have not seen :\n",
      "n\n",
      "      movieId                       title  genres\n",
      "9632   179119  The Death of Stalin (2017)  Comedy\n",
      "How do you rate this movie on a scale of 1-5, press n if you have not seen :\n",
      "n\n",
      "      movieId                 title                genres\n",
      "6569    55112  Shanghai Kiss (2007)  Comedy|Drama|Romance\n",
      "How do you rate this movie on a scale of 1-5, press n if you have not seen :\n",
      "n\n",
      "      movieId                           title  genres\n",
      "2880     3851  I'm the One That I Want (2000)  Comedy\n",
      "How do you rate this movie on a scale of 1-5, press n if you have not seen :\n",
      "n\n",
      "      movieId                 title        genres\n",
      "1396     1914  Smoke Signals (1998)  Comedy|Drama\n",
      "How do you rate this movie on a scale of 1-5, press n if you have not seen :\n",
      "n\n",
      "      movieId               title  genres\n",
      "2395     3177  Next Friday (2000)  Comedy\n",
      "How do you rate this movie on a scale of 1-5, press n if you have not seen :\n",
      "3\n",
      "      movieId               title          genres\n",
      "2629     3515  Me Myself I (2000)  Comedy|Romance\n",
      "How do you rate this movie on a scale of 1-5, press n if you have not seen :\n",
      "4\n",
      "      movieId                     title          genres\n",
      "8669   121342  Carry on Cruising (1962)  Comedy|Romance\n",
      "How do you rate this movie on a scale of 1-5, press n if you have not seen :\n",
      "n\n",
      "      movieId              title                     genres\n",
      "6762    59814  Ex Drummer (2007)  Comedy|Crime|Drama|Horror\n",
      "How do you rate this movie on a scale of 1-5, press n if you have not seen :\n",
      "3\n",
      "      movieId                 title                                   genres\n",
      "7733    90647  Puss in Boots (2011)  Adventure|Animation|Comedy|Fantasy|IMAX\n",
      "How do you rate this movie on a scale of 1-5, press n if you have not seen :\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "user_rating = movie_rater(df_movies, 4, 'Comedy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***If you're struggling to come up with the above function, you can use this list of user ratings to complete the next segment***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'userId': 1000, 'movieId': 3177, 'rating': '3'},\n",
       " {'userId': 1000, 'movieId': 3515, 'rating': '4'},\n",
       " {'userId': 1000, 'movieId': 59814, 'rating': '3'},\n",
       " {'userId': 1000, 'movieId': 90647, 'rating': '5'}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Making Predictions With the New Ratings***\\\n",
    "Now that you have new ratings, you can use them to make predictions for this new user. The proper way this should work is:\n",
    "\n",
    "* add the new ratings to the original ratings DataFrame, read into a `surprise` dataset \n",
    "* train a model using the new combined DataFrame\n",
    "* make predictions for the user\n",
    "* order those predictions from highest rated to lowest rated\n",
    "* return the top n recommendations with the text of the actual movie (rather than just the index number) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add the new ratings to the original ratings DataFrame\n",
    "user_ratings = pd.DataFrame(user_rating)\n",
    "new_ratings_df = pd.concat([new_df, user_ratings], axis=0)\n",
    "new_data = Dataset.load_from_df(new_ratings_df,reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x1a38c54e550>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train a model using the new combined DataFrame\n",
    "svd_ = SVD(n_factors= 50, reg_all=0.05)\n",
    "svd_.fit(new_data.build_full_trainset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions for the user\n",
    "# you'll probably want to create a list of tuples in the format (movie_id, predicted_score)\n",
    "list_of_movies = []\n",
    "for m_id in new_df['movieId'].unique():\n",
    "    list_of_movies.append( (m_id,svd_.predict(1000,m_id)[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# order the predictions from highest to lowest rated\n",
    "ranked_movies = sorted(list_of_movies, key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " For the final component of this challenge, it could be useful to create a function `recommended_movies()` that takes in the parameters:\n",
    "* `user_ratings`: list - list of tuples formulated as (user_id, movie_id) (should be in order of best to worst for this individual)\n",
    "* `movie_title_df`: DataFrame \n",
    "* `n`: int - number of recommended movies \n",
    "\n",
    "The function should use a `for` loop to print out each recommended *n* movies in order from best to worst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendation #  1 :  602    Dr. Strangelove or: How I Learned to Stop Worr...\n",
      "Name: title, dtype: object \n",
      "\n",
      "Recommendation #  2 :  510    Silence of the Lambs, The (1991)\n",
      "Name: title, dtype: object \n",
      "\n",
      "Recommendation #  3 :  951    Chinatown (1974)\n",
      "Name: title, dtype: object \n",
      "\n",
      "Recommendation #  4 :  46    Usual Suspects, The (1995)\n",
      "Name: title, dtype: object \n",
      "\n",
      "Recommendation #  5 :  277    Shawshank Redemption, The (1994)\n",
      "Name: title, dtype: object \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# return the top n recommendations using the \n",
    "def recommended_movies(user_ratings,movie_title_df,n):\n",
    "        for idx, rec in enumerate(user_ratings):\n",
    "            title = movie_title_df.loc[movie_title_df['movieId'] == int(rec[0])]['title']\n",
    "            print('Recommendation # ', idx+1, ': ', title, '\\n')\n",
    "            n-= 1\n",
    "            if n == 0:\n",
    "                break\n",
    "            \n",
    "recommended_movies(ranked_movies,df_movies,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary:** We have got the chance to implement a collaborative filtering model as well as retrieve recommendations from that model. We also got the opportunity to add our own recommendations to the system to get new recommendations for yourself! Next, you will need to learn how to use Spark to make recommender systems."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
