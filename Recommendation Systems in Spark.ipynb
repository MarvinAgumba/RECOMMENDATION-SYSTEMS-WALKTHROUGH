{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06fc64d8-93da-4edb-97cd-3838f450a38a",
   "metadata": {},
   "source": [
    "# Building a Recommendation System in PySpark\n",
    "\n",
    "## Movies Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4285583-73cc-47e4-8a91-b2173c1fe0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# instantiate SparkSession object\n",
    "# spark = SparkSession.builder.master('local').getOrCreate()\n",
    "\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName('ALSExample').config('spark.driver.host', 'localhost')\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9367f97-a2ac-498a-93c2-523e717a6fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the dataset into pyspark DataFrame\n",
    "movie_ratings = spark.read.csv('ratings.csv', header='true', inferSchema='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "affbd074-eea6-444e-ae27-7e526873af9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('userId', 'int'),\n",
       " ('movieId', 'int'),\n",
       " ('rating', 'double'),\n",
       " ('timestamp', 'int')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking data types\n",
    "movie_ratings.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88ee3649-35ca-476e-82a6-7f3cfb2050c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop unwanted columns\n",
    "movie_ratings = movie_ratings.drop('timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5207fdbb-2fc5-408f-8e5e-6fa07ebe8fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data already preprocessed we proceed to fit ALS\n",
    "#Fitting the Alternating Least Squares Model\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "# split into training and testing sets\n",
    "(training, test) = movie_ratings.randomSplit([0.8, 0.2])\n",
    "\n",
    "# Build the recommendation model using ALS on the training data\n",
    "# Note we set cold start strategy to 'drop' to ensure we don't get NaN evaluation metrics\n",
    "als = ALS(maxIter=5,rank=4, regParam=0.01, userCol='userId', itemCol='movieId', ratingCol='rating',\n",
    "          coldStartStrategy='drop')\n",
    "\n",
    "# fit the ALS model to the training set\n",
    "model = als.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1083393-bffa-47a1-8acc-af0665a807da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 0.9821188167469224\n"
     ]
    }
   ],
   "source": [
    "#Evaluating model performance\n",
    "\n",
    "# importing appropriate library\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Evaluate the model by computing the RMSE on the test data\n",
    "predictions = model.transform(test)\n",
    "evaluator = RegressionEvaluator(metricName='rmse', labelCol='rating',\n",
    "                                predictionCol='prediction')\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print('Root-mean-square error = ' + str(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9221b295-5425-4f7d-b77f-f4e3b5f56530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cross-validation to Find the Optimal Model\n",
    "\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "# initialize the ALS model\n",
    "als_model = ALS(userCol='userId', itemCol='movieId', \n",
    "                ratingCol='rating', coldStartStrategy='drop')\n",
    "\n",
    "# create the parameter grid                 \n",
    "params = ParamGridBuilder()\\\n",
    "          .addGrid(als_model.regParam, [0.01, 0.001, 0.1])\\\n",
    "          .addGrid(als_model.rank, [4, 10, 50]).build()\n",
    "\n",
    "\n",
    "# instantiating crossvalidator estimator\n",
    "cv = CrossValidator(estimator=als_model, estimatorParamMaps=params,evaluator=evaluator,parallelism=4)\n",
    "best_model = cv.fit(movie_ratings)    \n",
    "\n",
    "# We see the best model has a rank of 50, so we will use that in our future models with this dataset\n",
    "best_model.bestModel.rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bb3b70b-6447-4fc5-ba04-449bd9ef3f5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(movieId=1, title='Toy Story (1995)', genres='Adventure|Animation|Children|Comedy|Fantasy'),\n",
       " Row(movieId=2, title='Jumanji (1995)', genres='Adventure|Children|Fantasy'),\n",
       " Row(movieId=3, title='Grumpier Old Men (1995)', genres='Comedy|Romance'),\n",
       " Row(movieId=4, title='Waiting to Exhale (1995)', genres='Comedy|Drama|Romance'),\n",
       " Row(movieId=5, title='Father of the Bride Part II (1995)', genres='Comedy')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Incorporating movie names\n",
    "movie_titles = spark.read.csv('movies.csv',header='true',inferSchema='true')\n",
    "movie_titles.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32616a2f-db81-4ae6-86e3-4ed5c09d719e",
   "metadata": {},
   "source": [
    "We will eventually be matching up the movie ids with the movie titles. In the cell below, create a function `name_retriever()` that takes in a `movie_id` and returns a string that represents the movie title. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "776b1695-7d63-4326-a224-14cb2d3e0f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_retriever(movie_id, movie_title_df):\n",
    "    return movie_title_df.where(movie_title_df.movieId == movie_id).take(1)[0]['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4527c30f-8d4f-499b-abae-61bfa55cc72c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Winnie the Pooh and the Blustery Day (1968)\n"
     ]
    }
   ],
   "source": [
    "print(name_retriever(1023, movie_titles))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f850d5e8-a408-44c1-b26a-9bb18be911aa",
   "metadata": {},
   "source": [
    "Now it's time to actually get some recommendations! The ALS model has built-in methods called `.recommendForUserSubset()` and `.recommendForAllUsers()`. We'll start off with using a subset of users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3770c70-5223-40eb-ac72-4a8c7746ad71",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = movie_ratings.select(als.getUserCol()).distinct().limit(1)\n",
    "userSubsetRecs = model.recommendForUserSubset(users, 10)\n",
    "recs = userSubsetRecs.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f05ed39-5632-4d9a-981f-b556d2e5e5db",
   "metadata": {},
   "source": [
    "We can now see we have a list of rows with recommended items. Now try and get the name of the top recommended movie by way of the function you just created, using number one item for this user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2ba2d2c-95f0-4bb5-af1e-e84522ed0383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Violet & Daisy (2011)'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use indexing to obtain the movie id of top predicted rated item\n",
    "first_recommendation = recs[0]['recommendations'][0][0]\n",
    "\n",
    "# use the name retriever function to get the values\n",
    "name_retriever(first_recommendation,movie_titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f277a7f5-3ea2-4e1c-869c-976014c66839",
   "metadata": {},
   "source": [
    "We can also make recommendations for everyone, although this will take longer. In the next line, we are creating an RDD with the top 5 recommendations for every user and then selecting one user to find out his predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ef8b6df-b396-487f-8e04-789be0c41d6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(userId=3, recommendations=[Row(movieId=91470, rating=7.31921911239624), Row(movieId=2017, rating=6.326812744140625), Row(movieId=101577, rating=6.122920989990234), Row(movieId=6932, rating=5.955191135406494), Row(movieId=3385, rating=5.838411808013916)])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations = model.recommendForAllUsers(5)\n",
    "recommendations.where(recommendations.userId == 3).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd7bc12-9048-4d82-beb7-d547522f512f",
   "metadata": {},
   "source": [
    "Now, it's time to put together all that you've learned in this section to create a function that will take in a new user and some movies they've rated and then return $n$ number of highest recommended movies. This function will have multiple different steps to it:\r\n",
    "\r\n",
    "* Adding the new ratings into the DataFrame (hint: look into using the `.union()` method) \r\n",
    "* Fitting the ALS model  \r\n",
    "* Make recommendations for the user of choice \r\n",
    "* Print out the names of the top $n$ recommendations in a reader-friendly manner "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c379638-a995-4642-8fa5-c53f21066c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rate new movies\n",
    "def new_user_recs(user_id, new_ratings, rating_df, movie_title_df, num_recs):\n",
    "    # turn the new_recommendations list into a spark DataFrame\n",
    "    new_user_ratings = spark.createDataFrame(new_ratings,rating_df.columns)\n",
    "    \n",
    "    # combine the new ratings df with the rating_df\n",
    "    movie_ratings_combined = rating_df.union(new_user_ratings)\n",
    "    \n",
    "    # split the dataframe into a train and test set\n",
    "#     (training, test) = movie_ratings_combined.randomSplit([0.8, 0.2],seed=0)\n",
    "    \n",
    "    # create an ALS model and fit it\n",
    "    als = ALS(maxIter=5,rank=50, regParam=0.01, userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\",\n",
    "          coldStartStrategy=\"drop\")\n",
    "    model = als.fit(movie_ratings_combined)\n",
    "    \n",
    "    # make recommendations for all users using the recommendForAllUsers method\n",
    "    recommendations = model.recommendForAllUsers(num_recs)\n",
    "    \n",
    "    # get recommendations specifically for the new user that has been added to the DataFrame\n",
    "    recs_for_user = recommendations.where(recommendations.userId == user_id).take(1)\n",
    "    \n",
    "    for ranking, (movie_id, rating) in enumerate(recs_for_user[0]['recommendations']):\n",
    "        movie_string = name_retriever(movie_id,movie_title_df)\n",
    "        print('Recommendation {}: {}  | predicted score :{}'.format(ranking+1,movie_string,rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d529a57-cb4b-435b-a0d2-b995a0a353e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendation 1: Princess Bride, The (1987)  | predicted score :5.555953025817871\n",
      "Recommendation 2: Star Wars: Episode IV - A New Hope (1977)  | predicted score :5.5542731285095215\n",
      "Recommendation 3: Forrest Gump (1994)  | predicted score :5.53633451461792\n",
      "Recommendation 4: Star Wars: Episode VI - Return of the Jedi (1983)  | predicted score :5.520097255706787\n",
      "Recommendation 5: Usual Suspects, The (1995)  | predicted score :5.494187831878662\n",
      "Recommendation 6: Monty Python and the Holy Grail (1975)  | predicted score :5.454071998596191\n",
      "Recommendation 7: Lord of the Rings: The Fellowship of the Ring, The (2001)  | predicted score :5.450919151306152\n",
      "Recommendation 8: Life Is Beautiful (La Vita è bella) (1997)  | predicted score :5.449873924255371\n",
      "Recommendation 9: Shawshank Redemption, The (1994)  | predicted score :5.444922924041748\n",
      "Recommendation 10: Highlander (1986)  | predicted score :5.437699317932129\n"
     ]
    }
   ],
   "source": [
    "user_id = 100000\n",
    "user_ratings_1 = [(user_id,3253,5),\n",
    "                  (user_id,2459,5),\n",
    "                  (user_id,2513,4),\n",
    "                  (user_id,6502,5),\n",
    "                  (user_id,1091,5),\n",
    "                  (user_id,441,4)]\n",
    "new_user_recs(user_id,\n",
    "             new_ratings=user_ratings_1,\n",
    "             rating_df=movie_ratings,\n",
    "             movie_title_df=movie_titles,\n",
    "             num_recs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59fb5cb-9211-4b39-b710-b335433a2889",
   "metadata": {},
   "source": [
    "***So here we have it! Our recommendation system is generating recommendations for the top 10 movies.***\n",
    "\n",
    "## Summary\r\n",
    "​We haveou built a model using Spark, performed some parameter selection, and updated the model every time new user preferences came in. You looked at how Spark's ALS implementation can be used to build a scalable and efficient recommendation system. You also saw that such systems can become computationally expensive and using them with an online system could be a problem with traditional computational platforms. Spark's distributed computing architecture provides a great solution to deploy such recommendation systems for real-world applications (think Amazon, Spotify)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b05af291-45d5-4518-aa13-2d774817c6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (spark-env)",
   "language": "python",
   "name": "spark-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
